{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.8.5 (default, Sep  4 2020, 07:30:14) \n",
      "[GCC 7.3.0]\n",
      "PyTorch Version: 1.7.1\n",
      "Cuda Version: 11.0\n",
      "CUDNN Version: 8005\n",
      "Numpy Version: 1.19.2\n",
      "Device is : cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"Python Version:\", sys.version)\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"Cuda Version:\", torch.version.cuda)\n",
    "print(\"CUDNN Version:\", torch.backends.cudnn.version())\n",
    "print('Numpy Version:', np.__version__)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device is : {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test batch shape: torch.Size([12, 3, 129, 129])\n",
      "Test result shape: torch.Size([12, 3888, 19, 19, 2])\n",
      "Test transform shape: torch.Size([12, 3888, 19, 19, 2])\n",
      "Test reconstruction shape: torch.Size([12, 3, 129, 129])\n",
      "MSE: tensor(3.6409e-09, device='cuda:0')\n",
      "MSE max: tensor(8.1275e-05, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# sanity chack preprended 09.06.21\n",
    "from lftdn.LFT import compact_LFT\n",
    "\n",
    "class wandbdummy_LFT():\n",
    "    def __init__(self, stride, win_pad):\n",
    "        self.stride = stride\n",
    "        self.window_padding_constrained = win_pad\n",
    "\n",
    "B, C, H, W = 12, 3, 129, 129\n",
    "N = 11\n",
    "torch.manual_seed(2021)\n",
    "#test_batch = torch.rand((B, C, H, W))\n",
    "#torch.save(test_batch, 'test_batch.pt')\n",
    "test_batch = torch.load('test_batch.pt')\n",
    "test_batch = test_batch.to(device)\n",
    "test_window = torch.ones((N,N)).to(device)\n",
    "print('Test batch shape:', test_batch.shape)\n",
    "\n",
    "test_LFT_config = wandbdummy_LFT(stride=4, win_pad=4)\n",
    "test_LFT_result = compact_LFT(test_batch, test_window, test_LFT_config)\n",
    "print('Test result shape:', test_LFT_result.shape)\n",
    "torch.save(test_LFT_result, 'new_LFT_out.pt')\n",
    "\n",
    "from asset.utils import getPhaseDiff, getPhaseAdd\n",
    "\n",
    "test_transform, _ = getPhaseDiff(test_LFT_result, test_LFT_result)\n",
    "test_LFT_result_transformed = getPhaseAdd(test_LFT_result, test_transform)\n",
    "print('Test transform shape:', test_transform.shape)\n",
    "\n",
    "from lftdn.LFT import compact_iLFT\n",
    "\n",
    "class wandbdummy_m_iLFT():\n",
    "    def __init__(self, stride, win_pad, H, W):\n",
    "        self.stride = stride\n",
    "        self.window_padding_constrained = win_pad\n",
    "        self.res_y_constrained = H\n",
    "        self.res_x_constrained = W\n",
    "\n",
    "test_iLFT_config = wandbdummy_m_iLFT(stride=test_LFT_config.stride, win_pad=test_LFT_config.window_padding_constrained, H=H, W=W)\n",
    "# move_window introduces considerable noise!\n",
    "move_window = True\n",
    "test_reconstruction, _ = compact_iLFT(test_LFT_result_transformed, test_window, test_transform, test_iLFT_config, move_window_according_T=move_window, channel=C)\n",
    "print('Test reconstruction shape:', test_reconstruction.shape)\n",
    "torch.save(test_reconstruction, 'new_iLFT_out.pt')\n",
    "\n",
    "MSE_reconstruction = (test_batch-test_reconstruction)**2\n",
    "print('MSE:', MSE_reconstruction.mean())\n",
    "print('MSE max:', MSE_reconstruction.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lftdn.LFT import compact_LFT\n",
    "\n",
    "class wandbdummy_LFT():\n",
    "    def __init__(self, stride, win_pad):\n",
    "        self.stride = stride\n",
    "        self.window_padding_constrained = win_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test batch shape: torch.Size([12, 3, 129, 129])\n",
      "Test result shape: torch.Size([12, 3888, 19, 19, 2])\n"
     ]
    }
   ],
   "source": [
    "B, C, H, W = 12, 3, 129, 129\n",
    "N = 11\n",
    "torch.manual_seed(2021)\n",
    "test_batch = torch.rand((B, C, H, W))\n",
    "#test_batch = torch.load('test_batch.pt')\n",
    "test_batch = test_batch.to(device)\n",
    "test_window = torch.ones((N,N)).to(device)\n",
    "print('Test batch shape:', test_batch.shape)\n",
    "\n",
    "test_LFT_config = wandbdummy_LFT(stride=4, win_pad=4)\n",
    "test_LFT_result = compact_LFT(test_batch, test_window, test_LFT_config)\n",
    "print('Test result shape:', test_LFT_result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test transform shape: torch.Size([12, 3888, 19, 19, 2])\n"
     ]
    }
   ],
   "source": [
    "from asset.utils import getPhaseDiff, getPhaseAdd\n",
    "\n",
    "test_transform, _ = getPhaseDiff(test_LFT_result, test_LFT_result)\n",
    "test_LFT_result_transformed = getPhaseAdd(test_LFT_result, test_transform)\n",
    "print('Test transform shape:', test_transform.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lftdn.LFT import compact_iLFT\n",
    "\n",
    "class wandbdummy_m_iLFT():\n",
    "    def __init__(self, stride, win_pad, H, W):\n",
    "        self.stride = stride\n",
    "        self.window_padding_constrained = win_pad\n",
    "        self.res_y_constrained = H\n",
    "        self.res_x_constrained = W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test reconstruction shape: torch.Size([12, 3, 129, 129])\n"
     ]
    }
   ],
   "source": [
    "test_iLFT_config = wandbdummy_m_iLFT(stride=test_LFT_config.stride, win_pad=test_LFT_config.window_padding_constrained, H=H, W=W)\n",
    "# move_window introduces considerable noise!\n",
    "move_window = True\n",
    "test_reconstruction, _ = compact_iLFT(test_LFT_result_transformed, test_window, test_transform, test_iLFT_config, move_window_according_T=move_window, channel=C)\n",
    "print('Test reconstruction shape:', test_reconstruction.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: tensor(3.6409e-09, device='cuda:0')\n",
      "MSE max: tensor(8.1275e-05, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "MSE_reconstruction = (test_batch-test_reconstruction)**2\n",
    "print('MSE:', MSE_reconstruction.mean())\n",
    "print('MSE max:', MSE_reconstruction.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test batch just fft shape: torch.Size([12, 3, 129, 129, 2])\n",
      "Test reconstruction just fft shape: torch.Size([12, 3, 129, 129])\n",
      "MSE for fft: tensor(1.8512e-14, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "from lftdn.custom_fft import custom_fft, custom_ifft\n",
    "\n",
    "test_batch_fft = custom_fft(test_batch)\n",
    "print('Test batch just fft shape:', test_batch_fft.shape)\n",
    "test_reconstruction_fft = custom_ifft(test_batch_fft)\n",
    "print('Test reconstruction just fft shape:', test_reconstruction_fft.shape)\n",
    "MSE_reconstruction_fft = (test_batch-test_reconstruction_fft)**2\n",
    "print('MSE for fft:', MSE_reconstruction_fft.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_2 = torch.rand((B,C,H,W))\n",
    "test_2_fft = custom_fft(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asset.utils import normalizeFFT\n",
    "\n",
    "def custom_ifft_old(T, real=True):\n",
    "    if real:\n",
    "        return torch.ifft(T, signal_ndim=2, normalized=normalizeFFT)[...,0]\n",
    "    else:\n",
    "        return torch.ifft(T, signal_ndim=2, normalized=normalizeFFT)\n",
    "\n",
    "def custom_fft_old(iT, real=True):\n",
    "    ###make complex again --- TEMP: use complex signal\n",
    "    if real:\n",
    "        iTC = torch.stack([iT, torch.zeros_like(iT,requires_grad=False)], dim=-1)\n",
    "        return torch.fft(iTC, signal_ndim=2, normalized=normalizeFFT)\n",
    "    ###convert to modified transformation\n",
    "    else:\n",
    "        return torch.fft(iT, signal_ndim=2, normalized=normalizeFFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-089a0910507e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_input_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_input_old\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtest_input_new\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0moutput_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_fft_old\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_input_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mifft_old\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_ifft_old\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_old\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-ce4756825db3>\u001b[0m in \u001b[0;36mcustom_fft_old\u001b[0;34m(iT, real)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0miTC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miTC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignal_ndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnormalizeFFT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;31m###convert to modified transformation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "B, C, H, W = 2, 3, 65, 129\n",
    "test_input_old = torch.rand((B,C,H,W), requires_grad=True)\n",
    "test_input_new = test_input_old .detach().clone()\n",
    "test_input_new.requires_grad = True\n",
    "output_old = custom_fft_old(test_input_old)\n",
    "ifft_old = custom_ifft_old(output_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from this point on, old fft cannot be called, as torch.fft becomes a module, not a function\n",
    "from torch.fft import fftn, ifftn\n",
    "\n",
    "def custom_ifft_new(T, real=True):\n",
    "    T = torch.view_as_complex(T)\n",
    "    if real:\n",
    "        res = ifftn(T, dim=(-2, -1), norm=\"forward\" if normalizeFFT else \"backward\")\n",
    "        return res.real\n",
    "    else:\n",
    "        res = ifftn(T, dim=(-2, -1), norm=\"forward\" if normalizeFFT else \"backward\")\n",
    "        return torch.view_as_real(res)\n",
    "\n",
    "def custom_fft_new(iT, real=True):\n",
    "    ###make complex again --- TEMP: use complex signal\n",
    "    if real:\n",
    "        iTC = torch.stack([iT, torch.zeros_like(iT,requires_grad=False)], dim=-1)\n",
    "        iTC = torch.view_as_complex(iTC)\n",
    "        res = fftn(iTC, dim=(-2, -1), norm=\"forward\" if normalizeFFT else \"backward\")\n",
    "        return torch.view_as_real(res)\n",
    "    ###convert to modified transformation\n",
    "    else:\n",
    "        iT = torch.view_as_complex(iT)\n",
    "        res = fftn(iT, dim=(-2, -1), norm=\"forward\" if normalizeFFT else \"backward\")\n",
    "        return torch.view_as_real(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_new = custom_fft_new(test_input_new)\n",
    "ifft_new = custom_ifft_new(output_new)\n",
    "print(f'Output of old func shape: {output_old.shape}')\n",
    "print(f'Output of new func shape: {output_new.shape}')\n",
    "print(f'Are these outputs close?: {((output_old - output_new)**2).mean()}')\n",
    "\n",
    "print(f'Output of old ifft shape: {ifft_old.shape}')\n",
    "print(f'Output of new ifft shape: {ifft_new.shape}')\n",
    "print(f'Are these outputs close?: {((ifft_old - ifft_new)**2).mean()}')\n",
    "\n",
    "L_old = ((test_input_old - ifft_old)**2).mean()\n",
    "L_new = ((test_input_new - ifft_new)**2).mean()\n",
    "\n",
    "print(f'Is the ifft according to old version close to the input? {L_old}')\n",
    "print(f'Is the ifft according to new version close to the input? {L_new}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_old = ifft_old.sum()\n",
    "sum_new = ifft_new.sum()\n",
    "sum_old.backward()\n",
    "sum_new.backward()\n",
    "print(f'Are the gradients of the fft, then ifft sums the same?: {torch.allclose(test_input_old.grad.data, test_input_new.grad.data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OLD FUNC OUT:\n",
    "Test batch shape: torch.Size([12, 3, 129, 129])\n",
    "Test result shape: torch.Size([12, 3888, 19, 19, 2])\n",
    "Test transform shape: torch.Size([12, 3888, 19, 19, 2])\n",
    "Test reconstruction shape: torch.Size([12, 3, 129, 129])\n",
    "MSE: tensor(3.6409e-09, device='cuda:0')\n",
    "MSE max: tensor(8.1275e-05, device='cuda:0')\n",
    "\n",
    "NEW FUNC OUT:\n",
    "Test batch shape: torch.Size([12, 3, 129, 129])\n",
    "Test result shape: torch.Size([12, 3888, 19, 19, 2])\n",
    "Test transform shape: torch.Size([12, 3888, 19, 19, 2])\n",
    "Test reconstruction shape: torch.Size([12, 3, 129, 129])\n",
    "MSE: tensor(3.6409e-09, device='cuda:0')\n",
    "MSE max: tensor(8.1275e-05, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "LFT_out_old = torch.load('old_LFT_out.pt')\n",
    "iLFT_out_old = torch.load('old_iLFT_out.pt')\n",
    "\n",
    "LFT_out_new = torch.load('new_LFT_out.pt')\n",
    "iLFT_out_new = torch.load('new_iLFT_out.pt')\n",
    "\n",
    "print(torch.allclose(LFT_out_old, LFT_out_new) and torch.allclose(iLFT_out_old, iLFT_out_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
